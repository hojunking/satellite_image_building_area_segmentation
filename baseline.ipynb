{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65881053-57fc-4d83-971c-d725f3348e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import wandb\n",
    "from typing import List, Union\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7f9239-1e8d-49cd-8cec-37e4a3f16a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020011e5-e18c-4c68-88e4-3dde347eb980",
   "metadata": {},
   "source": [
    "##### Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a84040-53e9-4672-a662-d09c25a4939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5, ## train:valid : 5 :1\n",
    "    'seed': 42,\n",
    "    'img_size': 224,\n",
    "    'epochs': 200,\n",
    "    'train_bs':64,\n",
    "    'valid_bs':64,\n",
    "    'lr': 1e-4, ## learning rate\n",
    "    'num_workers': 8,\n",
    "    'verbose_step': 1,\n",
    "    'patience' : 5,\n",
    "    'device': 'cuda:0',\n",
    "    'freezing': False,\n",
    "    'trainable_layer': 12,\n",
    "    'model_path': './models'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a405b2a-a008-42fe-a288-9507075c0db5",
   "metadata": {},
   "source": [
    "###### WANDB Init & Model save name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0741d0e3-ba0b-4cbc-a6d8-242979542997",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'satellite'\n",
    "time_now = dt.datetime.now()\n",
    "run_id = time_now.strftime(\"%Y%m%d%H%M\")\n",
    "project_name = category\n",
    "user = 'hojunking'\n",
    "run_name = project_name + '_' + run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c541ebe3-34f0-4053-8de8-5fb4c742087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 디코딩 함수\n",
    "def rle_decode(mask_rle, shape):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s [0:][::2], s [1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape [0]*shape [1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img [lo:hi] = 1\n",
    "    return img.reshape(shape)\n",
    "\n",
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels [1:]!= pixels [:-1])[0] + 1\n",
    "    runs [1::2] -= runs [::2]\n",
    "    return ' '. join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a20bb4-0818-43d2-88b7-9f8d3d662d1c",
   "metadata": {},
   "source": [
    "##### Aumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaf065c-d46a-4f6f-ba84-ee6cd4a8acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = A.Compose(    [   \n",
    "    A.RandomResizedCrop(p=1, height=CFG['img_size'] ,width=CFG['img_size'], scale=(0.25, 0.35),ratio=(0.90, 1.10)),\n",
    "    A.ColorJitter(always_apply=True, p=0.5, contrast=0.2, saturation=0.3, hue=0.2),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=True, p=1.0),\n",
    "     A.pytorch.transforms.ToTensorV2()\n",
    "])\n",
    "transform_test = A.Compose([\n",
    "    A.Resize(height = CFG['img_size'], width = CFG['img_size']),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=True, p=1.0),\n",
    "     A.pytorch.transforms.ToTensorV2()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9551c8a5-2e9d-489c-8470-f7a3bc41f4e3",
   "metadata": {},
   "source": [
    "##### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c9ebff-ce81-458e-9662-9f0cfecf230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, infer=False):\n",
    "        super(SatelliteDataset,self).__init__():\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['img_path']\n",
    "        image = cv2.imread('../Data/satellite/'+ img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "\n",
    "        mask_rle = self.data.iloc[idx, 2]\n",
    "        mask = rle_decode(mask_rle, (image.shape[0], image.shape[1]))\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24955461-4520-485a-bd96-f528ee02c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(df, trn_idx, val_idx):\n",
    "    \n",
    "    train_ = df.loc[trn_idx,:].reset_index(drop=True)\n",
    "    valid_ = df.loc[val_idx,:].reset_index(drop=True)\n",
    "        \n",
    "    train_ds = SatelliteDataset(train_, transform=transform_train, infer=True)\n",
    "    valid_ds = SatelliteDataset(valid_, transform=transform_test, infer=True)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=CFG['train_bs'],\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG['num_workers']\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=CFG['valid_bs'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf691f9c-4b6e-43f9-bb78-dd6a89feec86",
   "metadata": {},
   "source": [
    "##### Dice calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4668e2c1-a7c6-43e0-9004-8d34964dd997",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# No valid masks found, return None\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdice_score\u001b[39m(prediction: \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray, ground_truth: np\u001b[38;5;241m.\u001b[39marray, smooth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-7\u001b[39m):\u001b[38;5;66;03m#-> float:\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    Calculate Dice Score between two binary masks.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     intersection \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(prediction \u001b[38;5;241m*\u001b[39m ground_truth)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "def calculate_dice(pred_rle, gt_rle):\n",
    "    pred_mask = rle_decode(pred_rle, img_shape)\n",
    "    gt_mask = rle_decode(gt_rle, img_shape)\n",
    "\n",
    "\n",
    "    if np.sum(gt_mask) > 0 or np.sum(pred_mask) > 0:\n",
    "        return dice_score(pred_mask, gt_mask)\n",
    "    else:\n",
    "        return None  # No valid masks found, return None\n",
    "\n",
    "        \n",
    "def dice_score(prediction: np.array, ground_truth: np.array, smooth=1e-7):#-> float:\n",
    "    '''\n",
    "    Calculate Dice Score between two binary masks.\n",
    "    '''\n",
    "    intersection = np.sum(prediction * ground_truth)\n",
    "    return (2.0 * intersection + smooth) / (np.sum(prediction) + np.sum(ground_truth) + smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961ed7a7-c615-435e-9f5b-bedf09a1d898",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552f735c-6a97-47f8-9ff5-5491c3bbdf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net의 기본 구성 요소인 Double Convolution Block을 정의합니다.\n",
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "# 간단한 U-Net 모델 정의\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.dconv_down1 = double_conv(3, 64)\n",
    "        self.dconv_down2 = double_conv(64, 128)\n",
    "        self.dconv_down3 = double_conv(128, 256)\n",
    "        self.dconv_down4 = double_conv(256, 512)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
    "\n",
    "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
    "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
    "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
    "\n",
    "        self.conv_last = nn.Conv2d(64, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)   \n",
    "\n",
    "        x = self.dconv_down4(x)\n",
    "\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "\n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv2], dim=1)       \n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv1], dim=1)   \n",
    "\n",
    "        x = self.dconv_up1(x)\n",
    "\n",
    "        out = self.conv_last(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73059032-cb8d-4cd3-8fb5-97a505375f14",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d611093c-9acf-4bda-a2dc-331db93e8b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None):\n",
    "    t = time.time()\n",
    "    \n",
    "    # SET MODEL TRAINING MODE\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = None\n",
    "    loss_sum = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # MODEL PREDICTION\n",
    "        with torch.cuda.amp.autocast():\n",
    "            image_preds = model(imgs)   #output = model(input)\n",
    "            loss = loss_fn(image_preds, image_labels) # CRITERION\n",
    "            loss_sum+=loss.detach()\n",
    "            \n",
    "            # BACKPROPAGATION\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        \n",
    "            if running_loss is None:\n",
    "                running_loss = loss.item()\n",
    "            else:\n",
    "                running_loss = running_loss * .99 + loss.item() * .01    \n",
    "        \n",
    "            # TQDM VERBOSE_STEP TRACKING\n",
    "            if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n",
    "                description = f'epoch {epoch} loss: {running_loss:.4f}'\n",
    "                pbar.set_description(description)\n",
    "        \n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    \n",
    "    trn_loss = loss_sum/len(train_loader)\n",
    "    \n",
    "    return image_preds_all, trn_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100b7447-0fd4-4636-888e-452b49069a2e",
   "metadata": {},
   "source": [
    "##### Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf021536-7b86-4824-9516-98d8f9503b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None):\n",
    "    t = time.time()\n",
    "    \n",
    "    # SET MODEL VALID MODE\n",
    "    model.eval()\n",
    "    \n",
    "    loss_sum = 0\n",
    "    sample_num = 0\n",
    "    avg_loss = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    prop_result = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "    for step, (imgs, masks) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        masks = masks.to(device).long()\n",
    "        \n",
    "        # MODEL PREDICTION\n",
    "        image_preds = model(imgs)\n",
    "\n",
    "        # OUTPUT VALUE\n",
    "        pred_masks = torch.sigmoid(outputs).cpu().numpy()\n",
    "        pred_masks = np.squeeze(pred_masks, axis=1)\n",
    "        pred_masks = (pred_masks > 0.35).astype(np.uint8) # Threshold = 0.35\n",
    "        \n",
    "        for i in range(len(imgs)):\n",
    "            mask_rle = rle_encode(pred_masks[i])\n",
    "            if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1\n",
    "                prop_result.append(-1)\n",
    "            else:\n",
    "                prop_result.append(mask_rle)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [masks.detach().cpu().numpy()]\n",
    "        \n",
    "        loss = loss_fn(image_preds, masks)\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        loss_sum += loss.item()*masks.shape[0]\n",
    "        sample_num += masks.shape[0]\n",
    "        \n",
    "        # TQDM\n",
    "        description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n",
    "        pbar.set_description(description)\n",
    "\n",
    "    # CALCULATION DICE COEFFICIEN\n",
    "    pred_mask_rle = prop_result\n",
    "    gt_mask_rle = masks\n",
    "\n",
    "\n",
    "    dice_scores = Parallel(n_jobs=-1)(\n",
    "            delayed(calculate_dice)(pred_rle, gt_rle) for pred_rle, gt_rle in zip(pred_mask_rle, gt_mask_rle)\n",
    "    )\n",
    "    dice_scores = [score for score in dice_scores if score is not None]  # Exclude None values\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    val_loss = avg_loss/len(val_loader)\n",
    "    \n",
    "    return image_preds_all, val_loss, np.mean(dice_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8441c8df-b712-440e-8236-c982bc880a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    seed_everything(CFG['seed'])\n",
    "    \n",
    "    # # WANDB TRACKER INIT\n",
    "    # wandb.init(project=project_name, entity=user)\n",
    "    # wandb.config.update(CFG)\n",
    "    # wandb.run.name = run_name\n",
    "    # wandb.define_metric(\"Train Loss\", step_metric=\"epoch\")\n",
    "    # wandb.define_metric(\"Valid Loss\", step_metric=\"epoch\")\n",
    "    # wandb.define_metric(\"Train-Valid Accuracy\", step_metric=\"epoch\")\n",
    "    \n",
    "    model_dir = CFG['model_path'] + '/{}'.format(run_name)\n",
    "    train_dir = train.dir.values\n",
    "    best_fold = 0\n",
    "    best_f1 =0.0\n",
    "    print('Model: {}'.format(CFG['model']))\n",
    "    # MAKE MODEL DIR\n",
    "    if not os.path.isdir(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    train_df = pd.read_csv('../Data/satellite/' + csv_file)\n",
    "    # STRATIFIED K-FOLD DEFINITION\n",
    "    folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n",
    "    \n",
    "    # TEST PROCESS FOLD BREAK\n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "    print(f'Training start with fold: {fold} epoch: {CFG[\"epochs\"]} \\n')\n",
    "\n",
    "    # # EARLY STOPPING DEFINITION\n",
    "    # early_stopping = EarlyStopping(patience=CFG[\"patience\"], verbose=True)\n",
    "\n",
    "    # DATALOADER DEFINITION\n",
    "    train_loader, val_loader = prepare_dataloader(train_df, trn_idx, val_idx)\n",
    "\n",
    "    # MODEL & DEVICE DEFINITION \n",
    "    device = torch.device(CFG['device'])\n",
    "    model =UNet()\n",
    "    \n",
    "    # # MODEL FREEZING\n",
    "    # #model.freezing(freeze = CFG['freezing'], trainable_layer = CFG['trainable_layer'])\n",
    "    # if CFG['freezing'] ==True:\n",
    "    #     for name, param in model.named_parameters():\n",
    "    #         if param.requires_grad == True:\n",
    "    #             print(f\"{name}: {param.requires_grad}\")\n",
    "\n",
    "    model.to(device)\n",
    "    # MODEL DATA PARALLEL\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()   \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'])\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.5, step_size=5)\n",
    "\n",
    "    # CRITERION (LOSS FUNCTION)\n",
    "    loss_tr = torch.nn.BCEWithLogitsLoss()\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # wandb.watch(model, loss_tr, log='all')\n",
    "\n",
    "    start = time.time()\n",
    "    print(f'Fold: {fold}')\n",
    "    for epoch in range(CFG['epochs']):\n",
    "        print('Epoch {}/{}'.format(epoch, CFG['epochs'] - 1))\n",
    "\n",
    "        # TRAINIG\n",
    "        train_preds_all, train_loss = train_one_epoch(epoch, model, loss_tr,\n",
    "                                                                    optimizer, train_loader, device, scheduler=scheduler)\n",
    "        # wandb.log({'Train Accuracy':train_acc, 'Train Loss' : train_loss, 'Train F1': train_f1, 'epoch' : epoch})\n",
    "\n",
    "        # VALIDATION\n",
    "        with torch.no_grad():\n",
    "            valid_preds_all, valid_loss, valid_dice= valid_one_epoch(epoch, model, loss_fn,\n",
    "                                                                    val_loader, device, scheduler=None)\n",
    "            # wandb.log({'Valid Accuracy':valid_acc, 'Valid Loss' : valid_loss, 'Valid F1': valid_f1 ,'epoch' : epoch})\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{train_loss :.5f}] Val Loss : [{valid_loss :.5f}] Val F1 Score : [{valid_dice:.5f}]')\n",
    "        \n",
    "        # SAVE ALL RESULTS\n",
    "        valid_dice_list = []\n",
    "\n",
    "        # MODEL SAVE (THE BEST MODEL OF ALL OF FOLD PROCESS)\n",
    "        if valid_f1 > best_dice:\n",
    "            best_f1 = valid_dice\n",
    "            best_epoch = epoch\n",
    "            # SAVE WITH DATAPARARELLEL WRAPPER\n",
    "            #torch.save(model.state_dict(), (model_dir+'/{}.pth').format(CFG['model']))\n",
    "            # SAVE WITHOUT DATAPARARELLEL WRAPPER\n",
    "            torch.save(model.module.state_dict(), (model_dir+'/{}.pth').format(CFG['model']))\n",
    "\n",
    "        # # EARLY STOPPING\n",
    "        # stop = early_stopping(valid_f1)\n",
    "        # if stop:\n",
    "        #     print(\"stop called\")   \n",
    "        #     break\n",
    "\n",
    "    end = time.time() - start\n",
    "    time_ = str(datetime.timedelta(seconds=end)).split(\".\")[0]\n",
    "    print(\"time :\", time_)\n",
    "\n",
    "    # PRINT BEST F1 SCORE MODEL OF FOLD\n",
    "    best_index = valid_dice_list.index(max(valid_dice_list))\n",
    "    print(f'fold: {fold}, Best Epoch : {best_index}/ {len(valid_dice_list)}')\n",
    "    print(f'Best valid_dice_list : {valid_dice_list[best_index]:.5f}')\n",
    "    print('-----------------------------------------------------------------------')\n",
    "\n",
    "    # K-FOLD END\n",
    "    if valid_dice_list[best_index] > best_fold:\n",
    "        best_fold = valid_dice_list[best_index]\n",
    "        top_fold = fold\n",
    "    print(f'Best valid_dice: {best_fold} Top fold : {top_fold}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
