{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e13ed01-9b20-491b-93f3-3c4da7abc5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import wandb\n",
    "from typing import List, Union\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "562eb621-7242-4e4f-a86e-1dd9874730c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 디코딩 함수\n",
    "def rle_decode(mask_rle, shape):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s [0:][::2], s [1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape [0]*shape [1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img [lo:hi] = 1\n",
    "    return img.reshape(shape)\n",
    "\n",
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels [1:]!= pixels [:-1])[0] + 1\n",
    "    runs [1::2] -= runs [::2]\n",
    "    return ' '. join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b542e354-febf-4934-ac7b-0815d0c99a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, infer=False):\n",
    "        super(SatelliteDataset,self).__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['img_path']\n",
    "        image = cv2.imread('../Data/satellite/'+ img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "\n",
    "        mask_rle = self.df.iloc[idx]['mask_rle']\n",
    "        mask = rle_decode(mask_rle, (image.shape[0], image.shape[1]))\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c597f27-9dbc-45f8-92d7-065137031c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = A.Compose(    [   \n",
    "    A.RandomResizedCrop(p=1, height=224 ,width=224, scale=(0.25, 0.35),ratio=(0.90, 1.10)),\n",
    "    A.ColorJitter(always_apply=True, p=0.5, contrast=0.2, saturation=0.3, hue=0.2),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=True, p=1.0),\n",
    "     A.pytorch.transforms.ToTensorV2()\n",
    "])\n",
    "transform_test = A.Compose([\n",
    "    A.Resize(height = 224, width = 224),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=True, p=1.0),\n",
    "     A.pytorch.transforms.ToTensorV2()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5404a01-2954-4cbf-a2c7-3b8197c28cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net의 기본 구성 요소인 Double Convolution Block을 정의합니다.\n",
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "# 간단한 U-Net 모델 정의\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.dconv_down1 = double_conv(3, 64)\n",
    "        self.dconv_down2 = double_conv(64, 128)\n",
    "        self.dconv_down3 = double_conv(128, 256)\n",
    "        self.dconv_down4 = double_conv(256, 512)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
    "\n",
    "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
    "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
    "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
    "\n",
    "        self.conv_last = nn.Conv2d(64, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)   \n",
    "\n",
    "        x = self.dconv_down4(x)\n",
    "\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "\n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv2], dim=1)       \n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv1], dim=1)   \n",
    "\n",
    "        x = self.dconv_up1(x)\n",
    "\n",
    "        out = self.conv_last(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e76c953-90c1-4a8e-979c-87452d5086d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../Data/satellite/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a55fd0b-9651-4a67-9067-c7937b168aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=7140, step=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66b25dd1-6523-4c15-80ba-ab9da4570c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 초기화\n",
    "model = UNet().to(device)\n",
    "load_model = 'models' + '/satellite_202307270301/Unet.pth'\n",
    "test = pd.read_csv('../Data/satellite/train.csv').loc\n",
    "test_dataset = SatelliteDataset(0, df='./test.csv', transform=transform_test, infer=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=8)\n",
    "\n",
    "# MODEL DATA PARALLEL\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28b94d09-a564-4391-8a15-987d4313bd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SatelliteDataset at 0x7fec981ed550>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09bbfc0a-feb2-44ef-bec9-2070acddeed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3790/3790 [05:58<00:00, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 50176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    result = []\n",
    "    for images in tqdm(test_dataloader):\n",
    "        images = images.float().to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        masks = torch.sigmoid(outputs).cpu().numpy()\n",
    "        masks = np.squeeze(masks, axis=1)\n",
    "        masks = (masks > 0.35).astype(np.uint8) # Threshold = 0.35\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            mask_rle = rle_encode(masks[i])\n",
    "            if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1\n",
    "                result.append(-1)\n",
    "            else:\n",
    "                result.append(mask_rle)\n",
    "    print(mask_rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1122c35b-ee00-406f-9d72-9877cbf6ff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../Data/satellite/sample_submission.csv')\n",
    "submit['mask_rle'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0affc4c5-f16e-4eca-8d5f-dfe707eb5aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
